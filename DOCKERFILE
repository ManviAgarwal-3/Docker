# Use official Python runtime as base image
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install system dependencies required for PySpark and PostgreSQL
RUN apt-get update && apt-get install -y \
    openjdk-21-jdk \
    gcc \
    g++ \
    wget \
    && rm -rf /var/lib/apt/lists/*

# Download and install Spark
RUN wget -q https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz && \
    tar -xzf spark-3.5.0-bin-hadoop3.tgz && \
    mv spark-3.5.0-bin-hadoop3 /usr/local/spark && \
    rm spark-3.5.0-bin-hadoop3.tgz

# Copy requirements
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt psycopg2-binary

# Copy application code
COPY main.py .
COPY visualise.py .
COPY test.py .

# Copy input data
COPY Raw/ Raw/

# Create output directory
RUN mkdir -p output

# Set environment variables for PySpark
ENV PYSPARK_PYTHON=python3
ENV PYSPARK_DRIVER_PYTHON=python3
ENV SPARK_HOME=/usr/local/spark

# Default command
CMD ["python", "main.py"]
